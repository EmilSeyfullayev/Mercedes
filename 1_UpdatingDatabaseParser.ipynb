{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_UpdatingDatabaseParser.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1X-MufEaHoXNOuO47aAVi1ZMdajkakzf1",
      "authorship_tag": "ABX9TyNouzTQpH58Ugz7JqkHBd7O",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmilSeyfullayev/Mercedes/blob/main/1_UpdatingDatabaseParser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBNjgwTcm2KG"
      },
      "source": [
        "# #About first threee cells\n",
        "# #In order to use colab with google drive with no authentication each time you have run this cell\n",
        "# #Then you will have to run next cell to copy client_id, client secret and refresh_token\n",
        "# #once you did thah you paste them in third cell and by running third cell only you dont need to authenticate each time\n",
        "# # while third cell is run, adc.json file is created\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFAPWLsbm24F",
        "outputId": "8547bca4-6de2-418d-a8b1-059e26b17aab"
      },
      "source": [
        "# !cat adc.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"client_id\": \"32555940559.apps.googleusercontent.com\",\n",
            "  \"client_secret\": \"ZmssLNjJy2998hD4CTg2ejr2\",\n",
            "  \"refresh_token\": \"1//06-zowQDCYmCSCgYIARAAGAYSNwF-L9IrcEofp20bnjkSzrx00j3TuCmLeg8LB6mp-N4CSaC6I8DD0791tBo6d-ocjVrQ_7w-1OE\",\n",
            "  \"revoke_uri\": \"https://accounts.google.com/o/oauth2/revoke\",\n",
            "  \"scopes\": [\n",
            "    \"openid\",\n",
            "    \"https://www.googleapis.com/auth/userinfo.email\",\n",
            "    \"https://www.googleapis.com/auth/cloud-platform\",\n",
            "    \"https://www.googleapis.com/auth/appengine.admin\",\n",
            "    \"https://www.googleapis.com/auth/compute\",\n",
            "    \"https://www.googleapis.com/auth/accounts.reauth\",\n",
            "    \"https://www.googleapis.com/auth/drive\"\n",
            "  ],\n",
            "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
            "  \"type\": \"authorized_user\"\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "t5wnofEtm3IX",
        "outputId": "2f0b080d-a965-4b62-8504-b6b89f8ddb9a"
      },
      "source": [
        "# #50 pages is around for 1 day\n",
        "first_page_to_be_parsed = 0\n",
        "last_page_to_be_parsed = 2\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "import httplib2\n",
        "import json\n",
        "\n",
        "from google.colab import auth\n",
        "from oauth2client import GOOGLE_REVOKE_URI, GOOGLE_TOKEN_URI, client\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "\n",
        "auth_key = {\n",
        "  \"client_id\": \"32555940559.apps.googleusercontent.com\",\n",
        "  \"client_secret\": \"ZmssLNjJy2998hD4CTg2ejr2\",\n",
        "  \"refresh_token\": \"1//06-zowQDCYmCSCgYIARAAGAYSNwF-L9IrcEofp20bnjkSzrx00j3TuCmLeg8LB6mp-N4CSaC6I8DD0791tBo6d-ocjVrQ_7w-1OE\"\n",
        "}\n",
        "\n",
        "credentials = client.OAuth2Credentials(\n",
        "    access_token=None,\n",
        "    client_id=auth_key['client_id'],\n",
        "    client_secret=auth_key['client_secret'],\n",
        "    refresh_token=auth_key['refresh_token'],\n",
        "    token_expiry=None,\n",
        "    token_uri=GOOGLE_TOKEN_URI,\n",
        "    user_agent=None,\n",
        "    revoke_uri=GOOGLE_REVOKE_URI)\n",
        "\n",
        "credentials.refresh(httplib2.Http())\n",
        "credentials.authorize(httplib2.Http())\n",
        "cred = json.loads(credentials.to_json())\n",
        "cred['type'] = 'authorized_user'\n",
        "\n",
        "with open('adc.json', 'w') as outfile:\n",
        "  json.dump(cred, outfile)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import timezone, tzinfo\n",
        "import pytz\n",
        "import datetime         # datetime.datetime.now()\n",
        "import time             # time.sleep(int(secs))\n",
        "\n",
        "HOST = \"https://turbo.az/\"\n",
        "HEADERS = {\n",
        "    \"accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\",\n",
        "    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36\"\n",
        "}\n",
        "\n",
        "\n",
        "####################################################################################\n",
        "list_of_links = []\n",
        "dates_times = []\n",
        "vip_premium = []\n",
        "loans = []\n",
        "barters = []\n",
        "\n",
        "for page_number in range(first_page_to_be_parsed, last_page_to_be_parsed, 1):\n",
        "  URL = \"https://turbo.az/autos?page=\" + str(page_number+1) + \"&q%5Bmake%5D%5B%5D=\" + str(4)\n",
        "\n",
        "  requested_html = requests.get(URL, headers=HEADERS).content\n",
        "  parsed_page = BeautifulSoup(requested_html, \"html.parser\")\n",
        "\n",
        "  for product_section in parsed_page.find_all(\"div\", \"products\"):\n",
        "    # try:\n",
        "    product_section.find_previous_sibling(\"div\", {\"class\":\"products-title\"}).find_all(\"p\", {\"class\":\"products-title-amount\"})\n",
        "    # except AttributeError:\n",
        "    #   pass\n",
        "    # else:\n",
        "\n",
        "      #this is for parsing links in third section\n",
        "      for tag_consisiting_of_href in product_section.find_all(\"a\", class_=\"products-i-link\"):\n",
        "        list_of_links.append(HOST+tag_consisiting_of_href.get(\"href\"))\n",
        "\n",
        "      #this is for parsing dates and times in third section's each of the product (24)\n",
        "      # for date_and_time in product_section.findChildren(\"div\", recursive=False):\n",
        "        # try:\n",
        "        #   dates_times.append(date_and_time.find_all(\"div\", class_=\"products-bottom\")[0].text.split(\", \")[1])\n",
        "        \n",
        "        # except IndexError:\n",
        "        #   pass\n",
        "        \n",
        "        # else:\n",
        "\n",
        "        #   dates_times.append(\"Qeyd olunmayÄ±b\")\n",
        "\n",
        "      #this is for vip, premium, etc\n",
        "      for category in product_section.findChildren(\"div\", recursive=False):\n",
        "        vip_premium.append(category.get(\"class\"))\n",
        "\n",
        "      #this is for parsing loan availability information\n",
        "      for loan in product_section.findChildren(\"div\", recursive=False):\n",
        "        if loan.find_all('div', class_='products-loan')==[]:\n",
        "          loans.append(0)\n",
        "        else:\n",
        "          loans.append(1)\n",
        "\n",
        "      #this is for parsing barter availability information\n",
        "      for barter in product_section.findChildren(\"div\", recursive=False):\n",
        "        if barter.find_all('div', class_='products-barter')==[]:\n",
        "          barters.append(0)\n",
        "        else:\n",
        "          barters.append(1)\n",
        "\n",
        "      time.sleep(2) # in this place it will print out ok 8 times (as there are four sections)\n",
        "      print(\"Parsed page number is \"+str(page_number+1)+\" out of \"+str(last_page_to_be_parsed))\n",
        "    \n",
        "\n",
        "\n",
        "#All should be same length\n",
        "print(len(list_of_links))\n",
        "print(len(dates_times))\n",
        "print(len(vip_premium))\n",
        "print(len(loans))\n",
        "print(len(barters))\n",
        "\n",
        "\n",
        "##Compare number of parsed links to number of them existing in db\n",
        "import gspread_dataframe as gd\n",
        "import gspread as gs\n",
        "gc = gs.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "ws = gc.open(\"MercedesDataBase\").worksheet(\"sheet_1\")\n",
        "db_data = gd.get_as_dataframe(ws)\n",
        "\n",
        "existed_in_db_check = []\n",
        "\n",
        "for link in list_of_links:\n",
        "  if link not in list(db_data['Link']):\n",
        "    existed_in_db_check.append(0)\n",
        "  elif link in list(db_data['Link']):\n",
        "    existed_in_db_check.append(1)\n",
        "\n",
        "print(\"Number of parsed links is: \" + str(len(barters)) + \", number of them existing in db is: \" + str(sum(existed_in_db_check))) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ac7c28339400>\"\u001b[0;36m, line \u001b[0;32m81\u001b[0m\n\u001b[0;31m    for tag_consisiting_of_href in product_section.find_all(\"a\", class_=\"products-i-link\"):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUvAoYylOUZ1",
        "outputId": "6edfcff0-879e-4c77-9561-0fbb26965add"
      },
      "source": [
        "list_of_links"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--4FMt7uoWvz"
      },
      "source": [
        "descriptions = []\n",
        "number_of_looks = []\n",
        "productS_id = []\n",
        "phone_book = []\n",
        "avtosalon_name = []\n",
        "extras = []\n",
        "product_text = []\n",
        "location = []\n",
        "time_parsed = []\n",
        "date_parsed = []\n",
        "\n",
        "def car_properties_parser():\n",
        "\n",
        "  for link in list_of_links:\n",
        "\n",
        "    requested_html = requests.get(link, headers=HEADERS).content\n",
        "    parsed_page = BeautifulSoup(requested_html, \"html.parser\")\n",
        "\n",
        "    try:\n",
        "\n",
        "\n",
        "      #this is for 14 important descriptions of a car\n",
        "      for main_description_division in parsed_page.find_all(\"div\", class_=\"product-properties-value\")[0:14]: #14 in order not to consider Barter and kredit\n",
        "        descriptions.append(main_description_division.text)\n",
        "\n",
        "      #this is for parsing number of looks\n",
        "      looks_quantity = parsed_page.find_all(\"div\", {\"class\":\"product-statistics\"})[0].find_all(\"p\")[0].text.split(\" \")[2]\n",
        "      number_of_looks.append(looks_quantity)\n",
        "\n",
        "      #this is for parsing products id\n",
        "      product_id = parsed_page.find_all(\"div\", {\"class\":\"product-statistics\"})[0].find_all(\"p\")[2].text.split(\" \")[2]\n",
        "      productS_id.append(product_id)\n",
        "\n",
        "      #for parsing product text\n",
        "      try:\n",
        "        product_text.append(parsed_page.find(class_=\"product-text\").text)\n",
        "      except AttributeError:\n",
        "        product_text.append(\"No text for product\")\n",
        "\n",
        "      #for parsing extras\n",
        "      try:\n",
        "        extras.append(parsed_page.find(\"div\", class_=\"product-extras\").text)\n",
        "      except AttributeError:\n",
        "        extras.append(\"No extras for product\")\n",
        "\n",
        "      #this is for parsing phone numbers\n",
        "\n",
        "      try:\n",
        "        phone_book.append(parsed_page.find(class_='phone').text)\n",
        "\n",
        "      except AttributeError:\n",
        "        phones = []\n",
        "        for i in parsed_page.find_all(class_='shop-contact--phones-i'):\n",
        "          phones.append(i.text)\n",
        "        \n",
        "        phone_book.append(phones)\n",
        "\n",
        "      \n",
        "      #for avtosalon name\n",
        "      \n",
        "      try:\n",
        "        avtosalon_name.append(parsed_page.find(class_=\"shop--title\").text)\n",
        "      except AttributeError:\n",
        "        avtosalon_name.append(0)\n",
        "\n",
        "      try:\n",
        "        location.append(parsed_page.find(class_=\"shop-contact--location-map shop--open-location-modal\").find(\"img\").get('src').split(\"markers=\")[1].split(\"&size\")[0])\n",
        "      except AttributeError:\n",
        "        location.append(0)\n",
        "\n",
        "      date_parsed.append(datetime.datetime.now(pytz.timezone(\"Asia/Baku\")).strftime(\"%H:%M:%S\"))\n",
        "      time_parsed.append(datetime.datetime.now(pytz.timezone(\"Asia/Baku\")).strftime(\"%Y-%m-%d\"))\n",
        "\n",
        "      print(\"Parsed link number is \" + str(list_of_links.index(link)+1)+ \" out of \"+ str(len(list_of_links))+  \" links.\")\n",
        "      time.sleep(1)\n",
        "\n",
        "    except IndexError:\n",
        "\n",
        "      descriptions.extend(list([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n",
        "      number_of_looks.append(0)\n",
        "      productS_id.append(0)\n",
        "      phone_book.append(0)\n",
        "      avtosalon_name.append(0)\n",
        "      extras.append(0)\n",
        "      product_text.append(0)\n",
        "      location.append(0)\n",
        "      time_parsed.append(0)\n",
        "      date_parsed.append(0)\n",
        "\n",
        "      print(\"Zeros were parsed in link \"+ str(link))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2OTxRVLN1rm"
      },
      "source": [
        "car_properties_parser()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0zkGohO170d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "35cc0429-e31d-457f-9841-72fe4900df6b"
      },
      "source": [
        "###################################################\n",
        "print(int(len(descriptions)/14))\n",
        "print(len(number_of_looks))\n",
        "print(len(productS_id))\n",
        "print(len(phone_book))\n",
        "print(len(avtosalon_name))\n",
        "print(len(extras))\n",
        "print(len(product_text))\n",
        "print(len(location))\n",
        "print(len(time_parsed))\n",
        "print(len(date_parsed))\n",
        "print(len(list_of_links))\n",
        "print(len(dates_times))\n",
        "print(len(vip_premium))\n",
        "print(len(loans))\n",
        "print(len(barters))\n",
        "\n",
        "######################################################\n",
        "####Naming columns\n",
        "\n",
        "first_column_names = []\n",
        "\n",
        "html = requests.get(list_of_links[0], headers=HEADERS).content\n",
        "soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "for labels in soup.find_all(\"li\", class_=\"product-properties-i\"):\n",
        "  for label in labels.find_all(\"label\"):\n",
        "    first_column_names.append(label.text)\n",
        "\n",
        "data = pd.DataFrame(np.array(descriptions).reshape(-1, 14))\n",
        "\n",
        "data.columns = first_column_names\n",
        "\n",
        "data[\"Tarix_Saat\"] = dates_times\n",
        "data[\"Kateqoriya\"] = vip_premium\n",
        "data['BaxÄ±ÅlarÄ±n sayÄ±'] = number_of_looks\n",
        "data['MÉhsulun id-si'] = productS_id\n",
        "data['Link'] = list_of_links\n",
        "data['Kredit mÃ¼mkÃ¼ndÃ¼r'] = loans\n",
        "data['Barter mÃ¼mkÃ¼ndÃ¼r'] = barters\n",
        "data['ÆlaqÉ nÃ¶mrÉsi'] = phone_book\n",
        "data['Avtosalon adÄ±'] = avtosalon_name\n",
        "data['Ekstra parametrlÉr'] = extras\n",
        "data['MÉhsulun mÉtni'] = product_text\n",
        "data['YerlÉÅmÉ mÉkanÄ±'] = location\n",
        "data['Parsinq olunan tarix'] = date_parsed\n",
        "data['Parsinq olunan zaman'] = time_parsed\n",
        "\n",
        "##########################################################\n",
        "import gspread_dataframe as gd\n",
        "import gspread as gs\n",
        "gc = gs.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "ws_mdb = gc.open(\"MercedesDataBase\").worksheet(\"sheet_1\")\n",
        "db_data = gd.get_as_dataframe(ws_mdb)\n",
        "\n",
        "existed_in_db = []\n",
        "\n",
        "for link in list_of_links:\n",
        "  if link not in list(db_data['Link']):\n",
        "    existed_in_db.append(0)\n",
        "  elif link in list(db_data['Link']):\n",
        "    existed_in_db.append(1)\n",
        "\n",
        "data['existed_in_db'] = existed_in_db\n",
        "\n",
        "############################################################\n",
        "\n",
        "checkpoint = data\n",
        "data = data.iloc[::-1].reset_index(drop=True)\n",
        "\n",
        "############################################################\n",
        "\n",
        "##Prints sum of not existed cars vs existing in db\n",
        "data_to_be_added = data[data['existed_in_db']==0]\n",
        "print(\"Number of cars Not existed in DB is: \" + str(len(data_to_be_added)))\n",
        "data_existed_in_db = data[data['existed_in_db']==1]\n",
        "print(\"Number of cars existed in DB is: \" + str(len(data_existed_in_db)))\n",
        "\n",
        "###############################################################\n",
        "\n",
        "print(\"Length of data to be added: \" + str(data_to_be_added.shape[0]))\n",
        "\n",
        "###############################################################\n",
        "\n",
        "##Adds data which did not exist in db\n",
        "import gspread_dataframe as gd\n",
        "import gspread as gs\n",
        "gc = gs.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "ws_mdb = gc.open(\"MercedesDataBase\").worksheet(\"sheet_1\")\n",
        "ws_mdb.add_rows(data_to_be_added.shape[0])\n",
        "gd.set_with_dataframe(worksheet=ws_mdb, dataframe=data_to_be_added, include_index=False, include_column_header=False,\n",
        "                      row=ws_mdb.row_count+1)\n",
        "\n",
        "##################################################################\n",
        "\n",
        "data_existed_in_db_necessary_columns = data_existed_in_db[['QiymÉt', 'Tarix_Saat',\n",
        "       'Kateqoriya', 'BaxÄ±ÅlarÄ±n sayÄ±', 'MÉhsulun id-si', 'Link','ÆlaqÉ nÃ¶mrÉsi', \n",
        "       'Parsinq olunan tarix', 'Parsinq olunan zaman','existed_in_db']]\n",
        "\n",
        "##this is to write information for the first time\n",
        "# ws = gc.open(\"Mercedes_DB_Updated_info_of_existing_cars\").worksheet(\"sheet_1\")\n",
        "# gd.set_with_dataframe(ws, data_existed_in_db_necessary_columns, resize=True)\n",
        "\n",
        "#This is to add new data_existed_in_db_necessary_columns to existing database\n",
        "\n",
        "ws_updated = gc.open(\"Mercedes_DB_Updated_info_of_existing_cars\").worksheet(\"sheet_1\")\n",
        "ws_updated.add_rows(data_existed_in_db_necessary_columns.shape[0])\n",
        "\n",
        "gd.set_with_dataframe(worksheet=ws_updated, dataframe=data_existed_in_db_necessary_columns,\n",
        "                       include_index=False, include_column_header=False,\n",
        "                       row=ws_updated.row_count+1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "960\n",
            "960\n",
            "960\n",
            "960\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-f77468a70e51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mfirst_column_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_of_links\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHEADERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"html.parser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ0vFzH58eyP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dmpp_hYW8e-M"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJZmRQ2s8fJK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbYyOpZV8fNO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gsa83h48fQq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40DYlXYi8fUA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NeGByjR8fXW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQGQTPxM8faX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waV58Zcr8fdT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kcJ38tU2thA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMl6vx-3rKBv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}